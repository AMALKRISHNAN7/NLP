{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "IQc5FVUKaP1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paragraph - Sentence\n",
        "corpus = \"Hello all, Welcome to NLP Learning. All the best.\"\n",
        "from nltk.tokenize import sent_tokenize\n",
        "documents = sent_tokenize(corpus)\n",
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAJcv-_DbKTm",
        "outputId": "19b2b8af-16f2-4966-8a62-0db0fccb261e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello all, Welcome to NLP Learning...', 'All the best.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paragrah - Word\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(corpus)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCckUn5UcNr1",
        "outputId": "9438c04b-815e-434a-f195-18b05f5f457f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'all', ',', 'Welcome', 'to', 'NLP', 'Learning', '.', 'All', 'the', 'best', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence - Words\n",
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLniD4rTcdJE",
        "outputId": "16f537bd-e438-4c2a-9305-f64f4fa7fd6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'all', ',', 'Welcome', 'to', 'NLP', 'Learning', '.']\n",
            "['All', 'the', 'best', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dont treat . as seperate word\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(\"Hello all, Welcome to NLP Learning. All the best.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF1HEwyJdRpU",
        "outputId": "b598e789-aa96-43f8-a0c1-cb5e99856121"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'all',\n",
              " ',',\n",
              " 'Welcome',\n",
              " 'to',\n",
              " 'NLP',\n",
              " 'Learning.',\n",
              " 'All',\n",
              " 'the',\n",
              " 'best',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "NkOqg0RReLpt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
